---
title: "Final_Lab"
author: "Brandon Liunoras"
date: "2023-06-16"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("syuzhet")
library("ggplot2")
```


```{r, Data Load in}
#Separation of positive and negative reviews
review <- read.csv("D:/IST_718/review_df.csv")
negative <- review[review$is_negative == 1,]
positive <- review[review$is_negative == 0,]

```

```{r, Corpus creation}
TextDoc <- Corpus(VectorSource(review))
TextDoc_n <- Corpus(VectorSource(negative))
TextDoc_p <- Corpus(VectorSource(positive))
```

```{r, Textdoc all Reviews}
# all Reviews
#Replacing "/", "@" and "|" with space
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
TextDoc <- tm_map(TextDoc, toSpace, "/")
TextDoc <- tm_map(TextDoc, toSpace, "@")
TextDoc <- tm_map(TextDoc, toSpace, "\\|")
# Convert the text to lower case
TextDoc <- tm_map(TextDoc, content_transformer(tolower))
# Remove numbers
TextDoc <- tm_map(TextDoc, removeNumbers)
# Remove english common stopwords
TextDoc <- tm_map(TextDoc, removeWords, stopwords("english"))
# Remove your own stop word
# specify your custom stopwords as a character vector
TextDoc <- tm_map(TextDoc, removeWords, c("s", "company", "team")) 
# Remove punctuations
TextDoc <- tm_map(TextDoc, removePunctuation)
# Eliminate extra white spaces
TextDoc <- tm_map(TextDoc, stripWhitespace)
# Text stemming - which reduces words to their root form
TextDoc <- tm_map(TextDoc, stemDocument)
```

```{r, TextDoc negative reviews}
# negative Textdoc
#Replacing "/", "@" and "|" with space
TextDoc_n <- tm_map(TextDoc_n, toSpace, "/")
TextDoc_n <- tm_map(TextDoc_n, toSpace, "@")
TextDoc_n <- tm_map(TextDoc_n, toSpace, "\\|")
# Convert the text to lower case
TextDoc_n <- tm_map(TextDoc_n, content_transformer(tolower))
# Remove numbers
TextDoc_n <- tm_map(TextDoc_n, removeNumbers)
# Remove english common stopwords
TextDoc_n <- tm_map(TextDoc_n, removeWords, stopwords("english"))
# Remove your own stop word
# specify your custom stopwords as a character vector
TextDoc_n <- tm_map(TextDoc_n, removeWords, c("s", "company", "team")) 
# Remove punctuations
TextDoc_n <- tm_map(TextDoc_n, removePunctuation)
# Eliminate extra white spaces
TextDoc_n <- tm_map(TextDoc_n, stripWhitespace)
# Text stemming - which reduces words to their root form
TextDoc_n <- tm_map(TextDoc_n, stemDocument)
```

```{r, textdoc Positive Reviews}
# positive Textdoc
 #Replacing "/", "@" and "|" with space
TextDoc_p <- tm_map(TextDoc_p, toSpace, "/")
TextDoc_p <- tm_map(TextDoc_p, toSpace, "@")
TextDoc_p <- tm_map(TextDoc_p, toSpace, "\\|")
# Convert the text to lower case
TextDoc_p <- tm_map(TextDoc_p, content_transformer(tolower))
# Remove numbers
TextDoc_p <- tm_map(TextDoc_p, removeNumbers)
# Remove english common stopwords
TextDoc_p <- tm_map(TextDoc_p, removeWords, stopwords("english"))
# Remove your own stop word
# specify your custom stopwords as a character vector
TextDoc_p <- tm_map(TextDoc_p, removeWords, c("s", "company", "team")) 
# Remove punctuations
TextDoc_p <- tm_map(TextDoc_p, removePunctuation)
# Eliminate extra white spaces
TextDoc_p <- tm_map(TextDoc_p, stripWhitespace)
# Text stemming - which reduces words to their root form
TextDoc_p <- tm_map(TextDoc_p, stemDocument)
```

```{r, term document matrix all reviews}
# Build a term-document matrix
TextDoc_dtm <- TermDocumentMatrix(TextDoc)
dtm_m <- as.matrix(TextDoc_dtm)
# Sort by descearing value of frequency
dtm_v <- sort(rowSums(dtm_m),decreasing=TRUE)
dtm_d <- data.frame(word = names(dtm_v),freq=dtm_v)
# Display the top 5 most frequent words
head(dtm_d, 5)
```

```{r, Tdm positive reviews}
# Positive Reviews
# Build a term-document matrix
TextDoc_dtm_pos <- TermDocumentMatrix(TextDoc_p)
dtm_m_pos <- as.matrix(TextDoc_dtm_pos)
# Sort by descearing value of frequency
dtm_v_pos <- sort(rowSums(dtm_m_pos),decreasing=TRUE)
dtm_d_pos <- data.frame(word = names(dtm_v_pos),freq=dtm_v_pos)
# Display the top 5 most frequent words
head(dtm_d_pos, 5)
```

```{r, Tdm negative reviews}
# Build a term-document matrix
TextDoc_dtm_neg <- TermDocumentMatrix(TextDoc_n)
dtm_m_neg <- as.matrix(TextDoc_dtm_neg)
# Sort by descearing value of frequency
dtm_v_neg <- sort(rowSums(dtm_m_neg),decreasing=TRUE)
dtm_d_neg <- data.frame(word = names(dtm_v_neg),freq=dtm_v_neg)
# Display the top 5 most frequent words
head(dtm_d_neg, 5)
```

```{r}
# Plot the most frequent words all reviews
barplot(dtm_d[1:5,]$freq, las = 2, names.arg = dtm_d[1:5,]$word,
        col ="yellow", main ="Top 5 Most Frequent Words All Reviews",
        ylab = "Word frequencies")
```
  
```{r}
# Plot the most frequent words positive reviews
barplot(dtm_d_pos[1:5,]$freq, las = 2, names.arg = dtm_d_pos[1:5,]$word,
        col ="lightgreen", main ="Top 5 Most Frequent Words Positive Reviews",
        ylab = "Word frequencies")
```

```{r}
# Plot the most frequent words negative reviews
barplot(dtm_d_neg[1:5,]$freq, las = 2, names.arg = dtm_d_neg[1:5,]$word,
        col ="red", main ="Top 5 Most Frequent Words Negative Reviews",
        ylab = "Word frequencies")
```

```{r, all reviews wordcloud}
#generate word cloud all reviews
set.seed(1234)
wordcloud(words = dtm_d$word, freq = dtm_d$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
```

```{r, positive review wordcloud}
#generate word cloud
set.seed(1234)
wordcloud(words = dtm_d_pos$word, freq = dtm_d_pos$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
```

```{r, negative review wordcloud}
#generate word cloud
set.seed(1234)
wordcloud(words = dtm_d_neg$word, freq = dtm_d_neg$freq, min.freq = 5,
          max.words=100, random.order=FALSE, rot.per=0.40, 
          colors=brewer.pal(8, "Dark2"))
```


```{r}
# regular sentiment score using get_sentiment() function and method of your choice
# please note that different methods may have different scales
syuzhet_vector <- get_sentiment(review$comment, method="syuzhet")
# see the first row of the vector
head(syuzhet_vector)
# see summary statistics of the vector
summary(syuzhet_vector)

# bing
bing_vector <- get_sentiment(review$comment, method="bing")
head(bing_vector)
summary(bing_vector)
#affin
afinn_vector <- get_sentiment(review$comment, method="afinn")
head(afinn_vector)
summary(afinn_vector)
```

```{r}
# regular sentiment score using get_sentiment() function and method of your choice
# please note that different methods may have different scales
syuzhet_vector_pos <- get_sentiment(positive$comment, method="syuzhet")
# see the first row of the vector
head(syuzhet_vector_pos)
# see summary statistics of the vector
summary(syuzhet_vector_pos)

# bing
bing_vector_pos <- get_sentiment(positive$comment, method="bing")
head(bing_vector_pos)
summary(bing_vector_pos)
#affin
afinn_vector_pos <- get_sentiment(positive$comment, method="afinn")
head(afinn_vector_pos)
summary(afinn_vector_pos)
```

```{r}
# regular sentiment score using get_sentiment() function and method of your choice
# please note that different methods may have different scales
syuzhet_vector_neg <- get_sentiment(negative$comment, method="syuzhet")
# see the first row of the vector
head(syuzhet_vector_neg)
# see summary statistics of the vector
summary(syuzhet_vector_neg)

# bing
bing_vector_neg <- get_sentiment(negative$comment, method="bing")
head(bing_vector_neg)
summary(bing_vector_neg)
#affin
afinn_vector_neg <- get_sentiment(negative$comment, method="afinn")
head(afinn_vector_neg)
summary(afinn_vector_neg)
```


```{r}

#compare the first row of each vector using sign function
rbind(
  sign(head(syuzhet_vector)),
  sign(head(bing_vector)),
  sign(head(afinn_vector))
)
```

```{r}
# run nrc sentiment analysis to return data frame with each row classified as one of the following
# emotions, rather than a score: 
# anger, anticipation, disgust, fear, joy, sadness, surprise, trust 
# It also counts the number of positive and negative emotions found in each row
d<-get_nrc_sentiment(review$comment)
# head(d,10) - to see top 10 lines of the get_nrc_sentiment dataframe
head (d,10)
```

```{r}
#transpose
td<-data.frame(t(d))
#The function rowSums computes column sums across rows for each level of a grouping variable.
td_new <- data.frame(rowSums(td[2:253]))
#Transformation and cleaning
names(td_new)[1] <- "count"
td_new <- cbind("sentiment" = rownames(td_new), td_new)
rownames(td_new) <- NULL
td_new2<-td_new[1:8,]
#Plot One - count of words associated with each sentiment
quickplot(sentiment, data=td_new2, weight=count, geom="bar", fill=sentiment, ylab="count")+ggtitle("Review Sentiments")

```

```{r}
new_review <- data.frame(review[,2:4], afinn_vector, bing_vector, syuzhet_vector)
new_positive <- data.frame(positive[,2:4], afinn_vector_pos, bing_vector_pos, syuzhet_vector_pos)
new_negative <- data.frame(negative[,2:4], afinn_vector_neg, bing_vector_neg, syuzhet_vector_neg)
```

```{r}
ggplot(new_positive, aes(x=afinn_vector_pos)) + geom_density(color = "darkgreen") + 
  ggtitle('Positive AFinn Polarity Scores')

ggplot(new_negative, aes(x=afinn_vector_neg)) + geom_density(color = "darkred") + 
  ggtitle('Negative AFinn Polarity Scores')

ggplot(new_positive, aes(x=bing_vector_pos)) + geom_density(color = "darkgreen") + 
  ggtitle('Positive Bing Polarity Scores')

ggplot(new_negative, aes(x=bing_vector_neg)) + geom_density(color = "darkred") + 
  ggtitle('Negative Bing Polarity Scores')

ggplot(new_positive, aes(x=syuzhet_vector_pos)) + geom_density(color = "darkgreen") + 
  ggtitle('Positive Syuzhet Polarity Scores')

ggplot(new_negative, aes(x=syuzhet_vector_neg)) + geom_density(color = "darkred") + 
  ggtitle('Negative Syuzhet Polarity Scores')

```

